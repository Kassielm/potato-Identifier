#!/usr/bin/env python3
"""
Script de teste para verificar NPU dentro do container
"""

import os
import sys
import subprocess
import time

def test_npu_detection():
    """Testa detecÃ§Ã£o do NPU"""
    print("ğŸ” Verificando detecÃ§Ã£o do NPU...")
    
    # Verificar dispositivos VIP
    vip_devices = ['/dev/vipnpu', '/dev/galcore']
    found_devices = []
    
    for device in vip_devices:
        if os.path.exists(device):
            found_devices.append(device)
            print(f"âœ… Dispositivo encontrado: {device}")
        else:
            print(f"âŒ Dispositivo nÃ£o encontrado: {device}")
    
    return len(found_devices) > 0

def test_delegate_loading():
    """Testa carregamento de delegates"""
    print("\nğŸ”§ Testando carregamento de delegates...")
    
    try:
        import tflite_runtime.interpreter as tflite
        
        # Testar delegate VX
        delegate_paths = [
            '/usr/lib/libvx_delegate.so',
            '/usr/lib/aarch64-linux-gnu/libvx_delegate.so',
            '/opt/venv/lib/python3.*/site-packages/tflite_runtime/libvx_delegate.so'
        ]
        
        for path in delegate_paths:
            if '*' in path:
                # Expandir wildcard
                import glob
                matches = glob.glob(path)
                if matches:
                    path = matches[0]
                else:
                    continue
            
            if os.path.exists(path):
                try:
                    delegate = tflite.load_delegate(path)
                    print(f"âœ… Delegate carregado: {path}")
                    return True
                except Exception as e:
                    print(f"âŒ Erro ao carregar delegate {path}: {e}")
            else:
                print(f"âš ï¸ Delegate nÃ£o encontrado: {path}")
        
        return False
        
    except ImportError as e:
        print(f"âŒ Erro ao importar TensorFlow Lite: {e}")
        return False

def test_model_inference():
    """Testa inferÃªncia com modelo"""
    print("\nğŸ¯ Testando inferÃªncia com modelo...")
    
    try:
        import tflite_runtime.interpreter as tflite
        import numpy as np
        
        # Verificar se existe modelo quantizado
        model_paths = [
            '/app/data/models/best_float32_edgetpu.tflite',
            '/app/data/models/best_float32.tflite'
        ]
        
        model_path = None
        for path in model_paths:
            if os.path.exists(path):
                model_path = path
                break
        
        if not model_path:
            print("âŒ Nenhum modelo encontrado")
            return False
        
        print(f"ğŸ“„ Usando modelo: {model_path}")
        
        # Tentar carregar com delegate VX
        try:
            delegate = tflite.load_delegate('/usr/lib/libvx_delegate.so')
            interpreter = tflite.Interpreter(
                model_path=model_path,
                experimental_delegates=[delegate]
            )
            print("âœ… Modelo carregado com delegate VX")
        except:
            # Fallback para CPU
            interpreter = tflite.Interpreter(model_path=model_path)
            print("âš ï¸ Modelo carregado em CPU (fallback)")
        
        interpreter.allocate_tensors()
        
        # Obter informaÃ§Ãµes do modelo
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        print(f"ğŸ“Š Input shape: {input_details[0]['shape']}")
        print(f"ğŸ“Š Output shape: {output_details[0]['shape']}")
        
        # Teste com dados dummy
        input_shape = input_details[0]['shape']
        dummy_input = np.random.randint(0, 255, size=input_shape, dtype=np.uint8)
        
        start_time = time.time()
        interpreter.set_tensor(input_details[0]['index'], dummy_input)
        interpreter.invoke()
        inference_time = time.time() - start_time
        
        print(f"âš¡ Tempo de inferÃªncia: {inference_time:.3f}s")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro durante teste de inferÃªncia: {e}")
        return False

def main():
    """FunÃ§Ã£o principal"""
    print("ğŸ§ª Teste de NPU no Container")
    print("=" * 40)
    
    results = []
    
    # Teste 1: DetecÃ§Ã£o do NPU
    results.append(test_npu_detection())
    
    # Teste 2: Carregamento de delegates
    results.append(test_delegate_loading())
    
    # Teste 3: InferÃªncia com modelo
    results.append(test_model_inference())
    
    # Resultado final
    print("\nğŸ“‹ Resumo dos Testes:")
    print("=" * 30)
    
    tests = [
        "DetecÃ§Ã£o do NPU",
        "Carregamento de Delegates",
        "InferÃªncia com Modelo"
    ]
    
    for i, (test, result) in enumerate(zip(tests, results)):
        status = "âœ… PASSOU" if result else "âŒ FALHOU"
        print(f"{i+1}. {test}: {status}")
    
    success_rate = sum(results) / len(results) * 100
    print(f"\nğŸ¯ Taxa de Sucesso: {success_rate:.1f}%")
    
    if success_rate >= 66.7:
        print("ğŸ‰ NPU estÃ¡ funcionando adequadamente!")
        return 0
    else:
        print("âš ï¸ Alguns problemas detectados com o NPU")
        return 1

if __name__ == "__main__":
    sys.exit(main())
